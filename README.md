# Support details for why few shot and detail of Few-Shot Prompting Method for Dataset Generation

This project analyzes the quality of reviews generated by large language models (LLMs) using zero-shot and few-shot prompting strategies. It includes a script to read and process review generation methodologies and prompt templates from a structured file.

## ğŸ“ Files

- `Review.pdf`: Contains detailed information on BLEU score comparisons between human-written and LLM-generated reviews, as well as domain-specific few-shot prompting strategies.

## ğŸ“Œ Features

- Reads and displays structured text content.
- Highlights differences in output quality between zero-shot and few-shot LLM prompts.
- Contains prompting templates across multiple domains:
  - E-Commerce
  - Hotel
  - Book
  - Movie
  - Restaurant

